{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load .env specifically from the current notebook directory\n",
    "load_dotenv(os.path.join(os.getcwd(), \".env\"))\n",
    "\n",
    "# 2. Setup path to import 'src'\n",
    "if os.path.exists(os.path.join(os.getcwd(), 'src')):\n",
    "    sys.path.append(os.getcwd())\n",
    "elif os.path.exists(os.path.join(os.getcwd(), '..', 'src')):\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.dataset import Cifar10DataManager\n",
    "from src.model import build_model\n",
    "from src.training import train_epoch, validate\n",
    "\n",
    "# Setup\n",
    "PROJECT_NAME = os.getenv(\"WANDB_PROJECT\", \"cifar10_mlops_project\")\n",
    "ENTITY = os.getenv(\"WANDB_ENTITY\", None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Checking for Feedback Artifacts...\")\n",
    "\n",
    "# 1. Initialize Run\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"automated_retraining\", tags=[\"retrain\"])\n",
    "\n",
    "# 2. Check/Download Feedback\n",
    "try:\n",
    "    artifact = run.use_artifact(f'{ENTITY}/{PROJECT_NAME}/cifar10-feedback:latest', type='dataset')\n",
    "    artifact_dir = artifact.download(root=\".\")\n",
    "    feedback_path = os.path.join(artifact_dir, \"feedback_v1.npy\")\n",
    "    \n",
    "    if os.path.exists(feedback_path):\n",
    "        feedback_data = np.load(feedback_path)\n",
    "        print(f\"Found {len(feedback_data)} feedback samples to integrate.\")\n",
    "    else:\n",
    "        print(\"No feedback data found.\")\n",
    "        feedback_data = []\n",
    "except Exception as e:\n",
    "    print(f\"No feedback artifact found (or no new feedback): {e}\")\n",
    "    feedback_data = []\n",
    "\n",
    "if len(feedback_data) > 0:\n",
    "    # 3. Fetch Best Config & Model from W&B (Cloud Source of Truth)\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    # Try to resolve Sweep ID - checks env first (if passed via CI/CD), then assumes we want the latest\n",
    "    sweep_id = os.getenv(\"SWEEP_ID\")\n",
    "    if not sweep_id:\n",
    "        sweeps = api.project(PROJECT_NAME, entity=ENTITY).sweeps()\n",
    "        if len(sweeps) > 0:\n",
    "            sweep_id = sweeps[0].id\n",
    "            print(f\"Using default latest sweep: {sweep_id}\")\n",
    "    \n",
    "    if not sweep_id:\n",
    "        print(\"Skipping: No Sweep ID found to base retraining on.\")\n",
    "        run.finish()\n",
    "        sys.exit(0)\n",
    "\n",
    "    sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{sweep_id}\")\n",
    "    best_run = sweep.best_run()\n",
    "    config = best_run.config\n",
    "    \n",
    "    # Download Base Model\n",
    "    artifacts = best_run.logged_artifacts()\n",
    "    model_artifact = [a for a in artifacts if a.type == \"model\"][0]\n",
    "    model_dir = model_artifact.download(root=\"./models\")\n",
    "    model_path = glob.glob(os.path.join(model_dir, \"*.pth\"))[0]\n",
    "    \n",
    "    # Data Setup\n",
    "    dm = Cifar10DataManager(data_dir=\"./data\")\n",
    "    # Ensuring data is present - relies on dm.prepare_initial_split or previous steps\n",
    "    # Ideally use artifact again:\n",
    "    # run.use_artifact(f'{ENTITY}/{PROJECT_NAME}/cifar10_dataset:latest').download(\"./data\")\n",
    "    \n",
    "    train_loader_base, test_loader = dm.get_loaders(config['batch_size'], config['architecture_option'])\n",
    "    \n",
    "    # 4. Create Augmented Dataset\n",
    "    sim_data_subset = dm.get_simulation_data() \n",
    "    \n",
    "    class FeedbackDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, subset, feedback_indices, transform=None):\n",
    "            self.subset = subset\n",
    "            self.indices = [int(x[0]) for x in feedback_indices]\n",
    "            self.transform = transform\n",
    "        def __len__(self): return len(self.indices)\n",
    "        def __getitem__(self, idx):\n",
    "            sim_idx = self.indices[idx]\n",
    "            image, label = self.subset[sim_idx]\n",
    "            if self.transform: image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "    train_transform, _ = dm.get_transforms(config['architecture_option'])\n",
    "    feedback_ds = FeedbackDataset(sim_data_subset, feedback_data, transform=train_transform)\n",
    "    \n",
    "    full_train_set = ConcatDataset([train_loader_base.dataset, feedback_ds])\n",
    "    full_train_loader = DataLoader(full_train_set, batch_size=config['batch_size'], shuffle=True, num_workers=0)\n",
    "    \n",
    "    print(f\"Retraining on {len(full_train_set)} samples...\")\n",
    "    \n",
    "    # 5. Retrain\n",
    "    model = build_model(config['architecture_option']).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(2):\n",
    "        print(f\"Retraining Epoch {epoch+1}...\")\n",
    "        loss = train_epoch(model, full_train_loader, criterion, optimizer, device)\n",
    "        _, acc = validate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss:.4f} Acc: {acc:.2f}%\")\n",
    "        wandb.log({\"retrain_loss\": loss, \"retrain_acc\": acc})\n",
    "        \n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), \"./models/model_retrained_v2.pth\")\n",
    "    \n",
    "    art = wandb.Artifact(f\"model-retrained-v2\", type=\"model\")\n",
    "    art.add_file(\"./models/model_retrained_v2.pth\")\n",
    "    run.log_artifact(art)\n",
    "    print(\"Retrained model v2 saved and logged.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping retraining - no feedback data.\")\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
