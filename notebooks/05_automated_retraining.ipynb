{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import numpy as np\n",
    "from src.utils import load_env_vars\n",
    "from src.dataset import Cifar10DataManager\n",
    "from src.model import build_model\n",
    "from src.training import train_epoch, validate\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "\n",
    "# Setup\n",
    "env = load_env_vars()\n",
    "PROJECT_NAME = env.get(\"WANDB_PROJECT\", \"cifar10_mlops_project\")\n",
    "ENTITY = env.get(\"WANDB_ENTITY\", None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Checking for Feedback Artifacts...\")\n",
    "\n",
    "# 1. Initialize Run\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"automated_retraining\", tags=[\"retrain\"])\n",
    "\n",
    "# 2. Check/Download Feedback\n",
    "try:\n",
    "    # We look for the artifact created in the previous step\n",
    "    # Note: In a real automated pipeline, this would be triggered by a webhook or a specific pipeline orchestrator\n",
    "    # Here, we just pull the latest version of the feedback artifact\n",
    "    artifact = run.use_artifact(f'{ENTITY}/{PROJECT_NAME}/cifar10-feedback:latest', type='dataset')\n",
    "    artifact_dir = artifact.download()\n",
    "    feedback_path = os.path.join(artifact_dir, \"feedback_v1.npy\")\n",
    "    \n",
    "    if os.path.exists(feedback_path):\n",
    "        feedback_data = np.load(feedback_path)\n",
    "        print(f\"Found {len(feedback_data)} feedback samples to integrate.\")\n",
    "    else:\n",
    "        print(\"No feedback data found.\")\n",
    "        feedback_data = []\n",
    "except Exception as e:\n",
    "    print(f\"No feedback artifact found: {e}\")\n",
    "    feedback_data = []\n",
    "\n",
    "if len(feedback_data) > 0:\n",
    "    # 3. Load Base Dataset & Config\n",
    "    with open(\"../artifacts/best_config.json\", \"r\") as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    dm = Cifar10DataManager(data_dir=\"../data\")\n",
    "    train_loader_base, test_loader = dm.get_loaders(config['batch_size'], config['architecture_option'])\n",
    "    \n",
    "    # 4. Create \"Augmented\" Train Set (Base + Feedback)\n",
    "    # The feedback data contains (idx, label) from the SIMULATION split (which was held out).\n",
    "    # We need to construct a dataset from these specific indices.\n",
    "    \n",
    "    sim_data_subset = dm.get_simulation_data() # RAW PIL images\n",
    "    \n",
    "    # We need to wrap them to apply the same Transforms as training\n",
    "    class FeedbackDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, subset, feedback_indices, transform=None):\n",
    "            self.subset = subset\n",
    "            self.indices = [int(x[0]) for x in feedback_indices] # List of indices relative to sim_subset\n",
    "            self.transform = transform\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.indices)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            # Map valid 0..N index to the actual sim index\n",
    "            sim_idx = self.indices[idx]\n",
    "            image, label = self.subset[sim_idx]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "    train_transform, _ = dm.get_transforms(config['architecture_option'])\n",
    "    feedback_ds = FeedbackDataset(sim_data_subset, feedback_data, transform=train_transform)\n",
    "    \n",
    "    # Concatenate\n",
    "    full_train_set = ConcatDataset([train_loader_base.dataset, feedback_ds])\n",
    "    \n",
    "    full_train_loader = DataLoader(full_train_set, batch_size=config['batch_size'], shuffle=True, num_workers=0) # workers=0 avoids issues in some colab/win environments with specific loaders\n",
    "    \n",
    "    print(f\"Retraining on {len(full_train_set)} samples (Original + Feedback)...\")\n",
    "    \n",
    "    # 5. Retrain Model (Fine-tune Best Model)\n",
    "    model = build_model(config['architecture_option']).to(device)\n",
    "    model.load_state_dict(torch.load(\"../models/model_best_sweep.pth\", map_location=device))\n",
    "    \n",
    "    # Optimization (Lower LR for fine-tuning)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Conservative LR\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Quick Retrain (1-2 epochs)\n",
    "    for epoch in range(2):\n",
    "        print(f\"Retraining Epoch {epoch+1}...\")\n",
    "        loss = train_epoch(model, full_train_loader, criterion, optimizer, device)\n",
    "        _, acc = validate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss:.4f} Acc: {acc:.2f}%\")\n",
    "        wandb.log({\"retrain_loss\": loss, \"retrain_acc\": acc})\n",
    "        \n",
    "    # Save Retrained Model\n",
    "    torch.save(model.state_dict(), \"../models/model_retrained_v2.pth\")\n",
    "    \n",
    "    # Version Model v2\n",
    "    art = wandb.Artifact(f\"model-retrained-v2\", type=\"model\")\n",
    "    art.add_file(\"../models/model_retrained_v2.pth\")\n",
    "    run.log_artifact(art)\n",
    "    print(\"Retrained model v2 saved and logged.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping retraining.\")\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
