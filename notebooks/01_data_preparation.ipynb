{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb620cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in to W&B Project: cifar10_mlops_project\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "API key must be 40 characters long, yours was 86",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_224/2581093037.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Logging in to W&B Project: {PROJECT_NAME}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWANDB_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, referrer)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \"\"\"\n\u001b[1;32m     79\u001b[0m     \u001b[0m_handle_host_wandb_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     logged_in, _ = _login(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, referrer, update_api_key, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey_is_pre_configured\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_api_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_save_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_global_anonymous_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mtry_save_api_key\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mapikey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mapikey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWriteNetrcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mwrite_key\u001b[0;34m(settings, key, api)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"API key must be 40 characters long, yours was {len(key)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0mwrite_netrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: API key must be 40 characters long, yours was 86"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import wandb\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# ==========================================\n",
    "# 1. Environment Setup (Standalone)\n",
    "# ==========================================\n",
    "# Hardcoded Credentials (Run Alone)\n",
    "WANDB_API_KEY = \"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\"\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "ENTITY = \"amirbnsl\" # Explicitly set your W&B username here\n",
    "\n",
    "print(f\"Logging in to W&B Project: {PROJECT_NAME}\")\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Shared Code (Inlined from src/dataset.py)\n",
    "# ==========================================\n",
    "class Cifar10DataManager:\n",
    "    def __init__(self, data_dir=\"./data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = (0.4914, 0.4822, 0.4465)\n",
    "        self.std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    def get_transforms(self, architecture_option='standard'):\n",
    "        # Base transforms\n",
    "        transform_list = [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.mean, self.std)\n",
    "        ]\n",
    "        \n",
    "        train_transforms = [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4)\n",
    "        ] + transform_list\n",
    "\n",
    "        if architecture_option == 'upsample':\n",
    "            transform_list.insert(0, transforms.Resize(224))\n",
    "            train_transforms.insert(0, transforms.Resize(224))\n",
    "\n",
    "        return transforms.Compose(train_transforms), transforms.Compose(transform_list)\n",
    "\n",
    "    def prepare_initial_split(self):\n",
    "        \"\"\"\n",
    "        Downloads CIFAR-10.\n",
    "        Splits Test set (10k) into:\n",
    "        - Test (8k): For model evaluation\n",
    "        - Simulation (2k): For live traffic simulation (Holdout)\n",
    "        \"\"\"\n",
    "        print(f\"Downloading/Loading data in {self.data_dir}...\")\n",
    "        # Download raw data\n",
    "        train_set = torchvision.datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n",
    "        test_set = torchvision.datasets.CIFAR10(root=self.data_dir, train=False, download=True)\n",
    "        \n",
    "        # Split Test Set\n",
    "        indices = list(range(len(test_set)))\n",
    "        # Shuffle deterministically for reproducibility\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        test_indices = indices[:8000]\n",
    "        sim_indices = indices[8000:]\n",
    "        \n",
    "        # Save indices to disk to ensure we load the same split later\n",
    "        processed_dir = os.path.join(self.data_dir, \"processed\")\n",
    "        os.makedirs(processed_dir, exist_ok=True)\n",
    "        np.save(os.path.join(processed_dir, \"test_indices.npy\"), test_indices)\n",
    "        np.save(os.path.join(processed_dir, \"sim_indices.npy\"), sim_indices)\n",
    "        print(\"Data split indices created.\")\n",
    "        \n",
    "        return train_set, test_set, test_indices, sim_indices\n",
    "\n",
    "# ==========================================\n",
    "# 3. Execution Main\n",
    "# ==========================================\n",
    "\n",
    "# Initialize Data Manager\n",
    "dm = Cifar10DataManager(data_dir=\"./data\")\n",
    "\n",
    "# 1. Download & Prepare Initial Split\n",
    "# This downloads CIFAR-10 from Torchvision and creates the 40k/8k/2k split indices locally\n",
    "print(\"Downloading and splitting data...\")\n",
    "dm.prepare_initial_split()\n",
    "\n",
    "# 2. Versioning with W&B\n",
    "# We create a new run to log this dataset as the \"Source of truth\"\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"data_preparation\", name=\"cifar10_v1\")\n",
    "\n",
    "# We create an artifact that contains the entire data directory (Raw images + Split Indices)\n",
    "dataset_artifact = wandb.Artifact(\n",
    "    name=\"cifar10_dataset\", \n",
    "    type=\"dataset\", \n",
    "    description=\"CIFAR-10 Raw Data + Split Indices (Train/Test/Sim)\"\n",
    ")\n",
    "\n",
    "# Add the data directory to the artifact\n",
    "# Note: This uploads the whole ./data folder including the 'cifar-10-batches-py' and 'processed'\n",
    "dataset_artifact.add_dir(\"./data\")\n",
    "\n",
    "# Log it\n",
    "run.log_artifact(dataset_artifact)\n",
    "run.finish()\n",
    "\n",
    "print(\"Step 1 Complete: Dataset v1 logged to W&B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce43fff",
   "metadata": {},
   "source": [
    "# Data Preparation and Versioning\n",
    "\n",
    "This notebook downloads the CIFAR-10 dataset and versions it using Weights & Biases Artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# Project Configuration\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "ENTITY = None # Set this to your username if needed, usually inferred\n",
    "ARTIFACT_NAME = \"cifar10-raw-data\"\n",
    "DATA_DIR = \"../data/raw\"\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f008f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B Run for Data Preparation\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"data-preparation\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIFAR-10 Dataset\n",
    "print(\"Downloading CIFAR-10 dataset...\")\n",
    "# We use torchvision to download, it creates a folder 'cifar-10-batches-py' inside DATA_DIR\n",
    "dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a W&B Artifact\n",
    "artifact = wandb.Artifact(name=ARTIFACT_NAME, type=\"dataset\", description=\"Raw CIFAR-10 dataset from torchvision\")\n",
    "\n",
    "# Add the directory containing the dataset to the artifact\n",
    "# Torchvision CIFAR10 extracts to a folder inside root, usually. \n",
    "# Let's add the whole DATA_DIR content to be sure we capture it.\n",
    "artifact.add_dir(DATA_DIR)\n",
    "\n",
    "# Log the artifact to W&B\n",
    "print(\"Logging artifact to W&B...\")\n",
    "run.log_artifact(artifact)\n",
    "print(\"Artifact logged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
