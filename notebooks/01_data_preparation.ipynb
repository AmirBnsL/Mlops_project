{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Ensure we can import from src (assuming notebook is in 'notebooks' dir)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import wandb\n",
    "from src.utils import load_env_vars\n",
    "from src.dataset import Cifar10DataManager\n",
    "\n",
    "# Load Env (Colab users: Set these manually or upload .env)\n",
    "env = load_env_vars()\n",
    "# If .env failed (Colab), set standard keys\n",
    "if os.getenv(\"WANDB_API_KEY\") is None:\n",
    "    print(\"Please login to wandb manually or set environment variables.\")\n",
    "    wandb.login()\n",
    "\n",
    "PROJECT_NAME = env.get(\"WANDB_PROJECT\", \"cifar10_mlops_project\")\n",
    "\n",
    "# Initialize Data Manager\n",
    "# We download to '../data' relative to this notebook\n",
    "dm = Cifar10DataManager(data_dir=\"../data\")\n",
    "\n",
    "# 1. Download & Prepare Initial Split\n",
    "# This downloads CIFAR-10 and creates the 40k/8k/2k split indices\n",
    "print(\"Downloading and splitting data...\")\n",
    "dm.prepare_initial_split()\n",
    "\n",
    "# 2. Versioning with W&B\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"data_preparation\", name=\"cifar10_v1\")\n",
    "\n",
    "# We create an artifact that contains the entire data directory (Raw images + Split Indices)\n",
    "dataset_artifact = wandb.Artifact(\n",
    "    name=\"cifar10_dataset\", \n",
    "    type=\"dataset\", \n",
    "    description=\"CIFAR-10 Raw Data + Split Indices (Train/Test/Sim)\"\n",
    ")\n",
    "\n",
    "# Add the data directory to the artifact\n",
    "dataset_artifact.add_dir(\"../data\")\n",
    "\n",
    "# Log it\n",
    "run.log_artifact(dataset_artifact)\n",
    "run.finish()\n",
    "\n",
    "print(\"Step 1 Complete: Dataset v1 logged to W&B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce43fff",
   "metadata": {},
   "source": [
    "# Data Preparation and Versioning\n",
    "\n",
    "This notebook downloads the CIFAR-10 dataset and versions it using Weights & Biases Artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# Project Configuration\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "ENTITY = None # Set this to your username if needed, usually inferred\n",
    "ARTIFACT_NAME = \"cifar10-raw-data\"\n",
    "DATA_DIR = \"../data/raw\"\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f008f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B Run for Data Preparation\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"data-preparation\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIFAR-10 Dataset\n",
    "print(\"Downloading CIFAR-10 dataset...\")\n",
    "# We use torchvision to download, it creates a folder 'cifar-10-batches-py' inside DATA_DIR\n",
    "dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a W&B Artifact\n",
    "artifact = wandb.Artifact(name=ARTIFACT_NAME, type=\"dataset\", description=\"Raw CIFAR-10 dataset from torchvision\")\n",
    "\n",
    "# Add the directory containing the dataset to the artifact\n",
    "# Torchvision CIFAR10 extracts to a folder inside root, usually. \n",
    "# Let's add the whole DATA_DIR content to be sure we capture it.\n",
    "artifact.add_dir(DATA_DIR)\n",
    "\n",
    "# Log the artifact to W&B\n",
    "print(\"Logging artifact to W&B...\")\n",
    "run.log_artifact(artifact)\n",
    "print(\"Artifact logged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
