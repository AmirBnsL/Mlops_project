{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2613743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "from fastapi import FastAPI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ==========================================\n",
    "# 1. Environment & Setup\n",
    "# ==========================================\n",
    "load_dotenv(os.path.join(os.getcwd(), \".env\"))\n",
    "nest_asyncio.apply()\n",
    "\n",
    "PROJECT_NAME = os.getenv(\"WANDB_PROJECT\", \"cifar10_mlops_project\")\n",
    "ENTITY = os.getenv(\"WANDB_ENTITY\", None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ==========================================\n",
    "# 2. Shared Code (Inlined)\n",
    "# ==========================================\n",
    "\n",
    "class Cifar10DataManager:\n",
    "    def __init__(self, data_dir=\"./data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = (0.4914, 0.4822, 0.4465)\n",
    "        self.std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "    def get_transforms(self, architecture_option='standard'):\n",
    "        transform_list = [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.mean, self.std)\n",
    "        ]\n",
    "        train_transforms = [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4)\n",
    "        ] + transform_list\n",
    "\n",
    "        if architecture_option == 'upsample':\n",
    "            transform_list.insert(0, transforms.Resize(224))\n",
    "            train_transforms.insert(0, transforms.Resize(224))\n",
    "\n",
    "        return transforms.Compose(train_transforms), transforms.Compose(transform_list)\n",
    "\n",
    "    def get_simulation_data(self):\n",
    "        \"\"\"Returns the raw Simulation subset (PIL images) for inference\"\"\"\n",
    "        # Load Raw (no transform)\n",
    "        test_set_raw = torchvision.datasets.CIFAR10(root=self.data_dir, train=False, download=True, transform=None)\n",
    "        \n",
    "        # Load Indices\n",
    "        indices_path = os.path.join(self.data_dir, \"processed\", \"sim_indices.npy\")\n",
    "        if not os.path.exists(indices_path):\n",
    "             raise FileNotFoundError(\"Simulation indices not found. Ensure dataset is downloaded/ready.\")\n",
    "             \n",
    "        sim_indices = np.load(indices_path)\n",
    "        return Subset(test_set_raw, sim_indices)\n",
    "\n",
    "def build_model(architecture_option='standard', num_classes=10, pretrained=True):\n",
    "    model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "    if architecture_option == 'modified':\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        model.maxpool = nn.Identity()\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. Prepare Resources\n",
    "# ==========================================\n",
    "\n",
    "# 3.1 Fetch Data (if needed)\n",
    "# Simply instantiating DM will trigger download if missing via torchvision\n",
    "# But for indices, we should check/download artifact\n",
    "if not os.path.exists(\"./data/processed/sim_indices.npy\"):\n",
    "    print(\"Downloading dataset artifact for simulation indices...\")\n",
    "    run_init = wandb.init(project=PROJECT_NAME, job_type=\"download_only\")\n",
    "    run_init.use_artifact(f'{ENTITY}/{PROJECT_NAME}/cifar10_dataset:latest').download(\"./data\")\n",
    "    run_init.finish()\n",
    "\n",
    "dm = Cifar10DataManager(data_dir=\"./data\")\n",
    "\n",
    "# 3.2 Fetch Model\n",
    "api = wandb.Api()\n",
    "sweep_id = None\n",
    "if os.path.exists(\"artifacts/sweep_id.txt\"):\n",
    "    with open(\"artifacts/sweep_id.txt\", \"r\") as f:\n",
    "        sweep_id = f.read().strip()\n",
    "elif os.getenv(\"SWEEP_ID\"):\n",
    "    sweep_id = os.getenv(\"SWEEP_ID\")\n",
    "else:\n",
    "    sweeps = api.project(PROJECT_NAME, entity=ENTITY).sweeps()\n",
    "    if len(sweeps) > 0:\n",
    "        sweep_id = sweeps[0].id\n",
    "        print(f\"Using latest sweep: {sweep_id}\")\n",
    "    else:\n",
    "        raise ValueError(\"No SWEEP_ID found.\")\n",
    "\n",
    "sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "config = best_run.config\n",
    "\n",
    "print(f\"Loading Model from: {best_run.name}\")\n",
    "artifacts = best_run.logged_artifacts()\n",
    "model_artifact = [a for a in artifacts if a.type == \"model\"][0]\n",
    "model_dir = model_artifact.download(root=\"./models\")\n",
    "model_path = glob.glob(os.path.join(model_dir, \"*.pth\"))[0]\n",
    "\n",
    "# Load to Device\n",
    "model = build_model(config['architecture_option']).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Preapre Transform\n",
    "_, val_transform = dm.get_transforms(config['architecture_option'])\n",
    "\n",
    "# ==========================================\n",
    "# 4. FastAPI Application\n",
    "# ==========================================\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(payload: dict):\n",
    "    try:\n",
    "        idx = payload.get(\"index\")\n",
    "        # In a real scenario, payload is the image. Here we cheat and read from local disk by index\n",
    "        sim_data = dm.get_simulation_data()\n",
    "        image, _ = sim_data[idx] \n",
    "        \n",
    "        input_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            conf, pred = torch.max(probs, 1)\n",
    "            \n",
    "        return {\n",
    "            \"prediction\": int(pred.item()),\n",
    "            \"confidence\": float(conf.item())\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"error\")\n",
    "\n",
    "# Run Server in background\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "print(\"Services started... Waiting 5s for bootup...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# ==========================================\n",
    "# 5. Simulation & Feedback Loop\n",
    "# ==========================================\n",
    "\n",
    "wandb.init(project=PROJECT_NAME, job_type=\"deployment_simulation\")\n",
    "\n",
    "try:\n",
    "    sim_data = dm.get_simulation_data()\n",
    "    feedback_data = [] \n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    table = wandb.Table(columns=[\"index\", \"prediction\", \"ground_truth\", \"confidence\", \"correct\"])\n",
    "    \n",
    "    print(\"Running Simulation requests...\")\n",
    "    # Sample random indices\n",
    "    indices = np.random.choice(len(sim_data), min(30, len(sim_data)), replace=False)\n",
    "    \n",
    "    for idx in indices:\n",
    "        _, gt_label = sim_data[idx]\n",
    "        \n",
    "        try:\n",
    "            resp = requests.post(\"http://127.0.0.1:8000/predict\", json={\"index\": int(idx)})\n",
    "            if resp.status_code == 200:\n",
    "                res = resp.json()\n",
    "                if \"error\" in res:\n",
    "                    print(f\"Server Error for {idx}: {res['error']}\")\n",
    "                    continue\n",
    "                    \n",
    "                pred = res[\"prediction\"]\n",
    "                conf = res[\"confidence\"]\n",
    "                is_correct = (pred == gt_label)\n",
    "                \n",
    "                print(f\"Idx {idx}: Truth={classes[gt_label]} | Pred={classes[pred]} ({conf:.2f}) -> {'✅' if is_correct else '❌'}\")\n",
    "                table.add_data(idx, classes[pred], classes[gt_label], conf, is_correct)\n",
    "                \n",
    "                # Feedback Condition: If wrong, we label it and save it\n",
    "                if not is_correct:\n",
    "                    feedback_data.append((int(idx), int(gt_label)))\n",
    "            else:\n",
    "                print(f\"HTTP Error: {resp.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            \n",
    "    wandb.log({\"simulation_results\": table})\n",
    "    \n",
    "    # Save Feedback\n",
    "    if len(feedback_data) > 0:\n",
    "        print(f\"\\nCaptured {len(feedback_data)} failure cases for retraining.\")\n",
    "        np.save(\"feedback_v1.npy\", feedback_data)\n",
    "        \n",
    "        artifact = wandb.Artifact(\"cifar10-feedback\", type=\"dataset\")\n",
    "        artifact.add_file(\"feedback_v1.npy\")\n",
    "        wandb.log_artifact(artifact)\n",
    "        print(\"Feedback artifact logged to W&B.\")\n",
    "    else:\n",
    "        print(\"Model performed perfectly! No feedback generated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Simulation crashed: {e}\")\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "# Apply nest_asyncio to allow running uvicorn in a notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configuration\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "\n",
    "# --- AUTOMATION: READ SWEEP ID FROM FILE ---\n",
    "try:\n",
    "    with open(\"../artifacts/sweep_id.txt\", \"r\") as f:\n",
    "        SWEEP_ID = f.read().strip()\n",
    "    print(f\"Loaded Sweep ID: {SWEEP_ID}\")\n",
    "except FileNotFoundError:\n",
    "    SWEEP_ID = \"YOUR_SWEEP_ID\" \n",
    "    print(\"Sweep ID file not found. Please run notebook 02 first or set manually.\")\n",
    "\n",
    "ENTITY = None \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Best Model from W&B Registry\n",
    "def load_best_model():\n",
    "    api = wandb.Api()\n",
    "    # Try-catch or conditional check for valid ID\n",
    "    try:\n",
    "        sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{SWEEP_ID}\")\n",
    "        best_run = sweep.best_run()\n",
    "        print(f\"Loading best model from run: {best_run.id}\")\n",
    "        \n",
    "        artifacts = best_run.logged_artifacts()\n",
    "        model_artifact = None\n",
    "        for a in artifacts:\n",
    "            if a.type == \"model\":\n",
    "                model_artifact = a\n",
    "                break\n",
    "                \n",
    "        if model_artifact:\n",
    "            artifact_dir = model_artifact.download()\n",
    "            model_path = f\"{artifact_dir}/model_best_{best_run.id}.pth\"\n",
    "            \n",
    "            # Reconstruct model architecture\n",
    "            # Note: Ideally architecture config should be saved with the model or in config\n",
    "            model = torchvision.models.resnet18(pretrained=False)\n",
    "            model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "            \n",
    "            # If you used 'modified' architecture in sweep, you need to handle that check here too.\n",
    "            # For simplicity assuming standard/upsample backbone structure for loading weights\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            except:\n",
    "                # Fallback for modified architecture if keys don't match\n",
    "                model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "                model.maxpool = nn.Identity()\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                \n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(\"Model loaded successfully!\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "model = load_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d06794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define FastAPI App\n",
    "app = FastAPI()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Transform for inference\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict_image(data: dict):\n",
    "    # Simulate receiving an image array (simplified)\n",
    "    # In prod, you'd handle file uploads or base64 strings\n",
    "    try:\n",
    "        # Expecting a list of pixels or simple identifier for simulation\n",
    "        # Here we just fetch real data from CIFAR test set by index for simulation\n",
    "        idx = data.get(\"index\", 0)\n",
    "        \n",
    "        # Load dataset on the fly (inefficient for prod, okay for demo)\n",
    "        testset = torchvision.datasets.CIFAR10(root='../data/raw', train=False, download=True, transform=transform)\n",
    "        image, label = testset[idx]\n",
    "        \n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            confidence = probs[0][predicted.item()].item()\n",
    "            \n",
    "        return {\n",
    "            \"prediction\": classes[predicted.item()],\n",
    "            \"confidence\": confidence,\n",
    "            \"ground_truth\": classes[label],\n",
    "            \"correct\": predicted.item() == label\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# 3. Utilities to run Server in Notebook\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"warning\")\n",
    "\n",
    "# Start server in a separate thread\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "print(\"FastAPI server started at http://127.0.0.1:8000\")\n",
    "time.sleep(3) # Wait for startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Simulate Prediction Requests and Log to W&B\n",
    "wandb.init(project=PROJECT_NAME, job_type=\"production-monitoring\")\n",
    "\n",
    "# Create a W&B Table to log requests\n",
    "columns = [\"request_id\", \"input_index\", \"prediction\", \"confidence\", \"ground_truth\", \"correct\"]\n",
    "prediction_table = wandb.Table(columns=columns)\n",
    "\n",
    "correct_count = 0\n",
    "total_requests = 10\n",
    "\n",
    "print(\"Simulating 10 user requests...\")\n",
    "\n",
    "for i in range(total_requests):\n",
    "    # Randomly pick an image index from test set\n",
    "    idx = np.random.randint(0, 1000)\n",
    "    \n",
    "    payload = {\"index\": idx}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\"http://127.0.0.1:8000/predict\", json=payload)\n",
    "        result = response.json()\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"Request {i+1} failed: {result['error']}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Req {i+1}: Pred={result['prediction']}, True={result['ground_truth']} ({result['correct']})\")\n",
    "        \n",
    "        # Log to Table\n",
    "        prediction_table.add_data(\n",
    "            i+1, \n",
    "            idx, \n",
    "            result['prediction'], \n",
    "            result['confidence'], \n",
    "            result['ground_truth'], \n",
    "            result['correct']\n",
    "        )\n",
    "        \n",
    "        if result['correct']:\n",
    "            correct_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Calculate Production Accuracy\n",
    "prod_accuracy = correct_count / total_requests\n",
    "print(f\"\\nProduction Accuracy: {prod_accuracy * 100}%\")\n",
    "\n",
    "# Log accumulated metrics to W&B\n",
    "wandb.log({\n",
    "    \"production_accuracy\": prod_accuracy,\n",
    "    \"inference_requests\": prediction_table\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
