{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2613743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import nest_asyncio\n",
    "from src.utils import load_env_vars\n",
    "from src.dataset import Cifar10DataManager\n",
    "from src.model import build_model\n",
    "\n",
    "nest_asyncio.apply()\n",
    "env = load_env_vars()\n",
    "PROJECT_NAME = env.get(\"WANDB_PROJECT\", \"cifar10_mlops_project\")\n",
    "ENTITY = env.get(\"WANDB_ENTITY\", None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. Setup Inference App\n",
    "app = FastAPI()\n",
    "\n",
    "# Load Config & Model\n",
    "with open(\"../artifacts/best_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"Downloading Real Model for Simulation...\")\n",
    "# Fetch from W&B using sweep_id to find best run\n",
    "with open(\"../artifacts/sweep_id.txt\", \"r\") as f:\n",
    "    sweep_id = f.read().strip()\n",
    "\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "artifacts = best_run.logged_artifacts()\n",
    "model_artifact = [a for a in artifacts if a.type == \"model\"][0]\n",
    "model_dir = model_artifact.download(root=\"../models\")\n",
    "model_path = glob.glob(os.path.join(model_dir, \"*.pth\"))[0]\n",
    "\n",
    "print(f\"Loading model: {model_path}\")\n",
    "model = build_model(config['architecture_option']).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Helper Transforms (Need to match training transforms for normality)\n",
    "dm = Cifar10DataManager(data_dir=\"../data\")\n",
    "_, val_transform = dm.get_transforms(config['architecture_option'])\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(payload: dict):\n",
    "    try:\n",
    "        idx = payload.get(\"index\")\n",
    "        sim_data = dm.get_simulation_data()\n",
    "        image, _ = sim_data[idx] \n",
    "        input_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            conf, pred = torch.max(probs, 1)\n",
    "            \n",
    "        return {\n",
    "            \"prediction\": int(pred.item()),\n",
    "            \"confidence\": float(conf.item())\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# 2. Start Server\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"error\")\n",
    "\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "print(\"Services started... Waiting 5s\")\n",
    "time.sleep(5)\n",
    "\n",
    "# 3. Real Simulation Loop\n",
    "wandb.init(project=PROJECT_NAME, job_type=\"deployment_simulation\")\n",
    "\n",
    "sim_data = dm.get_simulation_data() # access the 2k holdout set\n",
    "feedback_data = [] # Store (image_index, correct_label)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "table = wandb.Table(columns=[\"index\", \"prediction\", \"ground_truth\", \"confidence\", \"correct\"])\n",
    "\n",
    "print(\"Running Simulation on 30 random samples...\")\n",
    "indices = np.random.choice(len(sim_data), 30, replace=False)\n",
    "\n",
    "for idx in indices:\n",
    "    # Ground Truth\n",
    "    _, gt_label = sim_data[idx]\n",
    "    \n",
    "    # Request Prediction\n",
    "    try:\n",
    "        resp = requests.post(\"http://127.0.0.1:8000/predict\", json={\"index\": int(idx)})\n",
    "        res = resp.json()\n",
    "        \n",
    "        pred = res[\"prediction\"]\n",
    "        conf = res[\"confidence\"]\n",
    "        \n",
    "        is_correct = (pred == gt_label)\n",
    "        \n",
    "        print(f\"Idx {idx}: Truth={classes[gt_label]} | Pred={classes[pred]} ({conf:.2f}) -> {'✅' if is_correct else '❌'}\")\n",
    "        \n",
    "        table.add_data(idx, classes[pred], classes[gt_label], conf, is_correct)\n",
    "        \n",
    "        if not is_correct:\n",
    "            # FEEDBACK LOOP: Capture failure\n",
    "            feedback_data.append((int(idx), int(gt_label)))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "\n",
    "wandb.log({\"simulation_results\": table})\n",
    "\n",
    "# 4. Create Feedback Artifact (v2 Dataset Increment)\n",
    "if len(feedback_data) > 0:\n",
    "    print(f\"\\nCreating Feedback Artifact with {len(feedback_data)} new labeled samples...\")\n",
    "    np.save(\"feedback_v1.npy\", feedback_data)\n",
    "    \n",
    "    artifact = wandb.Artifact(\"cifar10-feedback\", type=\"dataset\")\n",
    "    artifact.add_file(\"feedback_v1.npy\")\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(\"Feedback artifact logged. Triggering Automated Retraining...\")\n",
    "else:\n",
    "    print(\"No errors found! No retraining needed.\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "# Apply nest_asyncio to allow running uvicorn in a notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configuration\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "\n",
    "# --- AUTOMATION: READ SWEEP ID FROM FILE ---\n",
    "try:\n",
    "    with open(\"../artifacts/sweep_id.txt\", \"r\") as f:\n",
    "        SWEEP_ID = f.read().strip()\n",
    "    print(f\"Loaded Sweep ID: {SWEEP_ID}\")\n",
    "except FileNotFoundError:\n",
    "    SWEEP_ID = \"YOUR_SWEEP_ID\" \n",
    "    print(\"Sweep ID file not found. Please run notebook 02 first or set manually.\")\n",
    "\n",
    "ENTITY = None \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Best Model from W&B Registry\n",
    "def load_best_model():\n",
    "    api = wandb.Api()\n",
    "    # Try-catch or conditional check for valid ID\n",
    "    try:\n",
    "        sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{SWEEP_ID}\")\n",
    "        best_run = sweep.best_run()\n",
    "        print(f\"Loading best model from run: {best_run.id}\")\n",
    "        \n",
    "        artifacts = best_run.logged_artifacts()\n",
    "        model_artifact = None\n",
    "        for a in artifacts:\n",
    "            if a.type == \"model\":\n",
    "                model_artifact = a\n",
    "                break\n",
    "                \n",
    "        if model_artifact:\n",
    "            artifact_dir = model_artifact.download()\n",
    "            model_path = f\"{artifact_dir}/model_best_{best_run.id}.pth\"\n",
    "            \n",
    "            # Reconstruct model architecture\n",
    "            # Note: Ideally architecture config should be saved with the model or in config\n",
    "            model = torchvision.models.resnet18(pretrained=False)\n",
    "            model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "            \n",
    "            # If you used 'modified' architecture in sweep, you need to handle that check here too.\n",
    "            # For simplicity assuming standard/upsample backbone structure for loading weights\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            except:\n",
    "                # Fallback for modified architecture if keys don't match\n",
    "                model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "                model.maxpool = nn.Identity()\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                \n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(\"Model loaded successfully!\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "model = load_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d06794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define FastAPI App\n",
    "app = FastAPI()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Transform for inference\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict_image(data: dict):\n",
    "    # Simulate receiving an image array (simplified)\n",
    "    # In prod, you'd handle file uploads or base64 strings\n",
    "    try:\n",
    "        # Expecting a list of pixels or simple identifier for simulation\n",
    "        # Here we just fetch real data from CIFAR test set by index for simulation\n",
    "        idx = data.get(\"index\", 0)\n",
    "        \n",
    "        # Load dataset on the fly (inefficient for prod, okay for demo)\n",
    "        testset = torchvision.datasets.CIFAR10(root='../data/raw', train=False, download=True, transform=transform)\n",
    "        image, label = testset[idx]\n",
    "        \n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            confidence = probs[0][predicted.item()].item()\n",
    "            \n",
    "        return {\n",
    "            \"prediction\": classes[predicted.item()],\n",
    "            \"confidence\": confidence,\n",
    "            \"ground_truth\": classes[label],\n",
    "            \"correct\": predicted.item() == label\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# 3. Utilities to run Server in Notebook\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"warning\")\n",
    "\n",
    "# Start server in a separate thread\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "print(\"FastAPI server started at http://127.0.0.1:8000\")\n",
    "time.sleep(3) # Wait for startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Simulate Prediction Requests and Log to W&B\n",
    "wandb.init(project=PROJECT_NAME, job_type=\"production-monitoring\")\n",
    "\n",
    "# Create a W&B Table to log requests\n",
    "columns = [\"request_id\", \"input_index\", \"prediction\", \"confidence\", \"ground_truth\", \"correct\"]\n",
    "prediction_table = wandb.Table(columns=columns)\n",
    "\n",
    "correct_count = 0\n",
    "total_requests = 10\n",
    "\n",
    "print(\"Simulating 10 user requests...\")\n",
    "\n",
    "for i in range(total_requests):\n",
    "    # Randomly pick an image index from test set\n",
    "    idx = np.random.randint(0, 1000)\n",
    "    \n",
    "    payload = {\"index\": idx}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\"http://127.0.0.1:8000/predict\", json=payload)\n",
    "        result = response.json()\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"Request {i+1} failed: {result['error']}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Req {i+1}: Pred={result['prediction']}, True={result['ground_truth']} ({result['correct']})\")\n",
    "        \n",
    "        # Log to Table\n",
    "        prediction_table.add_data(\n",
    "            i+1, \n",
    "            idx, \n",
    "            result['prediction'], \n",
    "            result['confidence'], \n",
    "            result['ground_truth'], \n",
    "            result['correct']\n",
    "        )\n",
    "        \n",
    "        if result['correct']:\n",
    "            correct_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Calculate Production Accuracy\n",
    "prod_accuracy = correct_count / total_requests\n",
    "print(f\"\\nProduction Accuracy: {prod_accuracy * 100}%\")\n",
    "\n",
    "# Log accumulated metrics to W&B\n",
    "wandb.log({\n",
    "    \"production_accuracy\": prod_accuracy,\n",
    "    \"inference_requests\": prediction_table\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
