{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d132523e",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook demonstrates how to fetch the best model from a W&B Sweep and evaluate it on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Setup\n",
    "PROJECT_NAME = \"cifar10_mlops_project\"\n",
    "# REPLACE THIS WITH YOUR SWEEP ID FROM NOTEBOOK 02\n",
    "SWEEP_ID = \"YOUR_SWEEP_ID_HERE\" \n",
    "ENTITY = None # Your username\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Get the sweep\n",
    "if SWEEP_ID == \"YOUR_SWEEP_ID_HERE\":\n",
    "    print(\"Please set the SWEEP_ID variable in the previous cell.\")\n",
    "else:\n",
    "    sweep = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{SWEEP_ID}\")\n",
    "    best_run = sweep.best_run()\n",
    "    print(f\"Best Run ID: {best_run.id}\")\n",
    "    print(f\"Best Run Accuracy: {best_run.summary.get('val_acc')}\")\n",
    "\n",
    "    # Find the model artifact from this run\n",
    "    # We named it f\"model-best-{run.id}\" in notebook 02\n",
    "    artifact_name = f\"model-best-{best_run.id}:v0\" # version 0 is usually the first one\n",
    "    # Note: If you logged multiple times it might be v1, v2... or use 'latest'\n",
    "    \n",
    "    # Alternatively, list artifacts produced by the run\n",
    "    artifacts = best_run.logged_artifacts()\n",
    "    model_artifact = None\n",
    "    for a in artifacts:\n",
    "        if a.type == \"model\":\n",
    "            model_artifact = a\n",
    "            break\n",
    "            \n",
    "    if model_artifact:\n",
    "        print(f\"Downloading artifact: {model_artifact.name}\")\n",
    "        artifact_dir = model_artifact.download()\n",
    "        model_path = f\"{artifact_dir}/model_best_{best_run.id}.pth\"\n",
    "        print(f\"Model downloaded to: {model_path}\")\n",
    "    else:\n",
    "        print(\"No model artifact found for the best run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca04633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (Test Set Only)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='../data/raw', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define Model Architecture to load weights\n",
    "def build_model():\n",
    "    model = torchvision.models.resnet18(pretrained=False) # No need to download weights, we load ours\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 10)\n",
    "    return model\n",
    "\n",
    "if 'model_path' in locals():\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(\"Model path not defined. Did artifact download succeed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "if 'model' in locals():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
