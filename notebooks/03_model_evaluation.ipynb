{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa85a6df",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "# ==========================================\n",
        "# 1. Setup & Auth\n",
        "# ==========================================\n",
        "WANDB_API_KEY = \"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\"\n",
        "PROJECT_NAME = \"cifar10_mlops_project\"\n",
        "ENTITY = \"esi-sba-dz\"\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fce57e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2. Helpers (No Download)\n",
        "# ==========================================\n",
        "class Cifar10DataManager:\n",
        "    def __init__(self, data_dir=\"./data\"):\n",
        "        self.data_dir = data_dir\n",
        "        self.mean = (0.4914, 0.4822, 0.4465)\n",
        "        self.std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "    def get_loaders(self, batch_size, architecture_option='standard'):\n",
        "        transform_list = [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ]\n",
        "        # Only test transform needed for eval\n",
        "        test_transform = transforms.Compose(transform_list)\n",
        "        if architecture_option == 'upsample':\n",
        "            test_transform = transforms.Compose([transforms.Resize(224)] + transform_list)\n",
        "\n",
        "        # STRICT: download=False\n",
        "        test_set = torchvision.datasets.CIFAR10(root=self.data_dir, train=False, download=False, transform=test_transform)\n",
        "        \n",
        "        indices_path = os.path.join(self.data_dir, \"processed\", \"test_indices.npy\")\n",
        "        real_test_set = Subset(test_set, np.load(indices_path))\n",
        "        return DataLoader(real_test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def build_model(architecture_option='standard'):\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    if architecture_option == 'modified':\n",
        "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        model.maxpool = nn.Identity()\n",
        "    elif architecture_option == 'upsample':\n",
        "        pass\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5359a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. Fetch Artifacts\n",
        "# ==========================================\n",
        "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"evaluation\")\n",
        "\n",
        "print(\"Downloading Data Artifact...\")\n",
        "run.use_artifact(f'{ENTITY}/{PROJECT_NAME}/cifar10_dataset:latest', type='dataset').download(root=\"./data\")\n",
        "\n",
        "# Resolve Model\n",
        "api = wandb.Api()\n",
        "sweeps = api.project(PROJECT_NAME, entity=ENTITY).sweeps()\n",
        "sweep_id = sweeps[0].id if sweeps else os.getenv(\"SWEEP_ID\")\n",
        "best_run = api.sweep(f\"{ENTITY}/{PROJECT_NAME}/{sweep_id}\").best_run()\n",
        "config = best_run.config\n",
        "\n",
        "print(f\"Downloading Model from: {best_run.name}\")\n",
        "model_dir = best_run.logged_artifacts()[0].download(root=\"./models\")\n",
        "model_path = glob.glob(os.path.join(model_dir, \"*.pth\"))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c993df3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 4. Evaluation\n",
        "# ==========================================\n",
        "dm = Cifar10DataManager(data_dir=\"./data\")\n",
        "test_loader = dm.get_loaders(100, config['architecture_option'])\n",
        "\n",
        "model = build_model(config['architecture_option']).to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        all_preds.extend(torch.max(outputs, 1)[1].cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "    y_true=all_labels, preds=all_preds, \n",
        "    class_names=['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        ")})\n",
        "run.finish()\n",
        "print(\"Evaluation Complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
